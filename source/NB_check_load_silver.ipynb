{"cells":[{"cell_type":"code","execution_count":null,"id":"c5aebc63-edc5-4cca-aa4c-0d7b68c81ac9","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}},"tags":["parameters"]},"outputs":[],"source":["# Receive parameters\n","pipelineruntime = \"\"\n","executionYear = \"\"\n","executionMonth = \"\"\n","executionDay = \"\"\n","workspaceid = \"\"\n","lakehouseid = \"\"\n","files_action_silver = \"\""]},{"cell_type":"code","execution_count":null,"id":"fbe3d5c0-eba0-4672-a7cb-de22d61a84fb","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["!pip install great_expectations\n","\n","import json\n","import great_expectations as gx\n","\n","import pyspark.sql.types as types\n","from pyspark.sql.functions import *\n","\n","import traceback"]},{"cell_type":"code","execution_count":null,"id":"fc33caee-f919-44db-b267-c5f4f1fb1a97","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Create base path for Lakehouse\n","base_lakehouse_path = f\"abfss://{workspaceid}@onelake.dfs.fabric.microsoft.com/{lakehouseid}/\"\n","\n","# Get class from Python files for pipelineLog, validateData\n","sc.addPyFile(\"abfss://Global_Electronics_Retailer_Meta@onelake.dfs.fabric.microsoft.com/LH_Python_Files.Lakehouse/Files/FabricUDFManagement.py\")\n","from FabricUDFManagement import *\n","pipelineLogger = PipelineLogger()\n","validateData = ValidateData()\n","\n","# Instance of great_expectations\n","context = gx.get_context()\n","\n","# Create executionDate\n","executionDate = f\"{executionYear}-{executionMonth}-{executionDay}\"\n","\n","# Load to json array\n","bronze_to_silver_json_array = json.loads(files_action_silver)"]},{"cell_type":"code","execution_count":null,"id":"8a7fb588-5a15-43f1-8843-a501bbfc70bc","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Time\n","start_time = \"\"\n","end_time = \"\"\n","\n","# Error, status\n","error = \"\"\n","status = \"\"\n","\n","# Path\n","data_validate_path = \"\"\n","validator = None\n","\n","for bronze_to_silver_json in bronze_to_silver_json_array:\n","\n","    # Load to json_obj\n","    bronze_to_silver = json.loads(bronze_to_silver_json)\n","\n","    # Get information about task\n","    task_id = bronze_to_silver[\"task_id\"]\n","    task_name = bronze_to_silver[\"task_name\"]\n","    source_folder = bronze_to_silver[\"source_folder\"]\n","    target_schema = bronze_to_silver[\"target_schema\"]\n","    target_table = bronze_to_silver[\"target_table\"]\n","    phase = bronze_to_silver[\"phase\"]\n","\n","    # Validate data\n","    columnMissing = \"\"\n","    columnNull = \"\"\n","\n","    # Num Inserted\n","    numInserted = 0\n","\n","    # Check data\n","    # print(\"Task_id: \", task_id)\n","    # print(\"Task_name: \", task_name)\n","    # print(\"Source folder\", source_folder)\n","    # print(\"target_table\", target_table)\n","\n","    # Get start time of notebook\n","    start_time = spark.sql(''' SELECT from_utc_timestamp(CURRENT_TIMESTAMP(), 'Asia/Ho_Chi_Minh') as current_time ''') \\\n","                              .collect()[0][\"current_time\"].strftime('%Y-%m-%d %H:%M:%S')\n","\n","    # Validate authentication (Fake account)\n","    try:\n","        data_validate_path = f\"{base_lakehouse_path}/Files/Bronze/{source_folder}/{executionYear}/{executionMonth}/{executionDay}/{source_folder}_{executionYear}_{executionMonth}_{executionDay}.parquet\"\n","        validator = context.sources.pandas_default.read_parquet(data_validate_path)\n","    except:\n","        data_validate_path = f\"{base_lakehouse_path}/Files/Bronze/{source_folder}/{executionYear}/{executionMonth}/{executionDay}/{source_folder}_{executionYear}_{executionMonth}_{executionDay}.parquet\"\n","        validator = context.sources.pandas_default.read_parquet(data_validate_path)\n","\n","    try:\n","        # Check task\n","            # Task = 6, Customer\n","        if task_id == 6:\n","            col_check_match = [\"CustomerKey\", \"Gender\", \"Name\", \"City\", \"State_Code\", \"State\", \"Zip_Code\", \"Country\", \"Continent\", \"Birthday\"]\n","            col_check_null = \"CustomerKey\"\n","\n","            columnMissing = validateData.check_schema(validator, col_check_match)\n","            # columnNull = validateData.check_null(validator, col_check_null)\n","        \n","            # Task = 7, Stores\n","        elif task_id == 7:\n","            col_check_match = [\"StoreKey\", \"Country\", \"State\", \"Square_Meters\", \"Open_Date\"]\n","            col_check_null = \"StoreKey\"\n","\n","            columnMissing = validateData.check_schema(validator, col_check_match)\n","            # columnNull = validateData.check_null(validator, col_check_null)\n","            \n","            # Task = 8, Products\n","        elif task_id == 8:\n","            col_check_match = [\"ProductKey\", \"Product_Name\", \"Brand\", \"Color\", \"Unit_Cost_USD\", \"Unit_Price_USD\", \\\n","                               \"SubcategoryKey\", \"Subcategory\", \"CategoryKey\", \"Category\"]\n","            col_check_null = \"ProductKey\"\n","\n","            columnMissing = validateData.check_schema(validator, col_check_match)\n","            # columnNull = validateData.check_null(validator, col_check_null)\n","            s\n","            # Task = 9, Sales\n","        elif task_id == 9:\n","            col_check_match = [\"Order_Number\", \"Line_Item\", \"Order_Date\", \"Delivery_Date\", \"CustomerKey\", \"StoreKey\", \\\n","                               \"ProductKey\", \"Quantity\", \"Currency_Code\"]\n","            col_check_null = \"Order_Number\"\n","\n","            columnMissing = validateData.check_schema(validator, col_check_match)\n","            # columnNull = validateData.check_null(validator, col_check_null)\n","            \n","            # Task = 10, Exchange_Rates\n","        elif task_id == 10:\n","            col_check_match = [\"Date\", \"Currency\", \"Exchange\"]\n","            col_check_null = \"Currency\"\n","\n","            columnMissing = validateData.check_schema(validator, col_check_match)\n","            # columnNull = validateData.check_null(validator, col_check_null)\n","\n","        else:\n","            pass\n","\n","        # Check error \n","        if (columnMissing != \"\") or (columnNull != \"\"): \n","            error = \"Missing column or Have null value in data\"\n","            status = \"Failed\"\n","        else:\n","\n","            error = \"\"\n","            status = \"Success\"\n","\n","            # Read dataframe\n","            df_save_delta = spark.read.format(\"parquet\").load(data_validate_path)\n","\n","            # Set numInserted\n","            numInserted = df_save_delta.count()\n","\n","            # Save as delta\n","            df_save_delta.write.mode(\"overwrite\").option(\"parquet.vorder.enabled\",\"true\").format(\"delta\").save(f\"{base_lakehouse_path}/Tables/{target_table}\")\n","\n","    except:\n","        error = traceback.format_exc()\n","        status = \"Failed\"\n","        \n","\n","    # Get end time of notebook\n","    end_time = spark.sql(''' SELECT from_utc_timestamp(CURRENT_TIMESTAMP(), 'Asia/Ho_Chi_Minh') as current_time ''') \\\n","                              .collect()[0][\"current_time\"].strftime('%Y-%m-%d %H:%M:%S')\n","\n","    # Log pipeline run\n","    df_log = pipelineLogger.log_data(pipelineruntime, task_id, task_name, start_time, \\\n","                                     end_time, 0, numInserted, 0, columnMissing, columnNull, error, status, types, spark)\n","\n","    # Save log\n","    df_log.write.mode(\"append\").format(\"parquet\").save(f\"{base_lakehouse_path}/Files/Log_BronzetoSilver/{executionDate}/\")"]},{"cell_type":"code","execution_count":2,"id":"acce2ff4-1b5a-4c58-9c71-795d35393ec2","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-05-29T15:45:20.4485955Z","execution_start_time":"2024-05-29T15:45:12.6675562Z","livy_statement_state":"available","parent_msg_id":"11f03407-a123-49a7-a40d-a2c951390f19","queued_time":"2024-05-29T15:45:12.2467826Z","session_id":"4dd63d81-ff4b-422b-8596-7d4cb6c7109b","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":4,"statement_ids":[4]},"text/plain":["StatementMeta(, 4dd63d81-ff4b-422b-8596-7d4cb6c7109b, 4, Finished, Available)"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.synapse.widget-view+json":{"widget_id":"4f34a44f-9953-4e57-bb7e-c615b8977224","widget_type":"Synapse.DataFrame"},"text/plain":["SynapseWidget(Synapse.DataFrame, 4f34a44f-9953-4e57-bb7e-c615b8977224)"]},"metadata":{},"output_type":"display_data"}],"source":["# df_log = spark.read.format(\"parquet\").load(\"abfss://a2719874-ed1d-47f0-be1d-c88fd0db2547@onelake.dfs.fabric.microsoft.com/d81ba17b-89ed-46b5-a1a9-e020f10bf176/Files/Log_BronzetoSilver/2024-05-29/*.parquet\")\n","\n","# display(df_log.orderBy(\"TaskId\", ascending = True))"]}],"metadata":{"dependencies":{"lakehouse":{}},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","language":"Python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"synapse_widget":{"state":{"4f34a44f-9953-4e57-bb7e-c615b8977224":{"persist_state":{"view":{"chartOptions":{"aggregationType":"count","binsNumber":10,"categoryFieldKeys":["0"],"chartType":"bar","isStacked":false,"seriesFieldKeys":["0"],"wordFrequency":"-1"},"tableOptions":{},"type":"details"}},"sync_state":{"isSummary":false,"language":"scala","table":{"rows":[{"0":"2024-05-29T15:33:09.5574336Z","1":"6","2":"bronze_to_silver","3":"2024-05-29 22:41:09","4":"2024-05-29 22:41:19","5":"0","6":"15266","7":"0","8":"Success","9":"","10":"","11":"","index":1},{"0":"2024-05-29T15:33:09.5574336Z","1":"7","2":"bronze_to_silver","3":"2024-05-29 22:41:21","4":"2024-05-29 22:41:27","5":"0","6":"67","7":"0","8":"Success","9":"","10":"","11":"","index":2},{"0":"2024-05-29T15:33:09.5574336Z","1":"8","2":"bronze_to_silver","3":"2024-05-29 22:41:28","4":"2024-05-29 22:41:28","5":"0","6":"0","7":"0","8":"Failed","9":"Missed column: ['ProductName'], Unexpected column: ['Product_Name']","10":"","11":"Missing column or Have null value in data","index":3},{"0":"2024-05-29T15:33:09.5574336Z","1":"9","2":"bronze_to_silver","3":"2024-05-29 22:41:29","4":"2024-05-29 22:41:34","5":"0","6":"62884","7":"0","8":"Success","9":"","10":"","11":"","index":4},{"0":"2024-05-29T15:33:09.5574336Z","1":"10","2":"bronze_to_silver","3":"2024-05-29 22:41:35","4":"2024-05-29 22:41:40","5":"0","6":"11215","7":"0","8":"Success","9":"","10":"","11":"","index":5}],"schema":[{"key":"0","name":"PipelineRunTime","type":"string"},{"key":"1","name":"TaskId","type":"int"},{"key":"2","name":"TaskName","type":"string"},{"key":"3","name":"StartTime","type":"string"},{"key":"4","name":"EndTime","type":"string"},{"key":"5","name":"SourceRowsRead","type":"int"},{"key":"6","name":"NumTargetInserted","type":"int"},{"key":"7","name":"NumTargetUpdated","type":"int"},{"key":"8","name":"Status","type":"string"},{"key":"9","name":"ColumnMissing","type":"string"},{"key":"10","name":"ColumnNull","type":"string"},{"key":"11","name":"Error","type":"string"}],"truncated":false}},"type":"Synapse.DataFrame"}},"version":"0.1"},"widgets":{}},"nbformat":4,"nbformat_minor":5}
